Vancouver Crime Analysis Summary Report
This project* contains comprehensive analysis of crime trends in Vancouver, aiming to uncover insights and compare neighborhood crime patterns.
Project Objectives In my analytical journey through the crime data of Vancouver, I have anchored the explorations around key questions. These questions not only guide my methodologies but also ensure that the findings remain relevant, actionable, and aligned with the broader goals of understanding crime dynamics in the city. As we delve deep into the data, I seek to answer the following pivotal questions:
•	Descriptive Analysis: Explore historical crime data to observe trends, patterns, and variations in crime occurrences over time. Identify frequently occurring crimes and neighborhoods with high crime rates. Investigate possible seasonality and relationships with holidays.
•	Predictive Modeling: Utilize linear regression techniques to predict the city's crime rate up to the year 2035. Understand the potential impact of population growth on crime rates and project future changes in crime occurrences.
•	Neighborhood Comparison: Conduct a detailed comparison of crime rates among different neighborhoods. Uncover spatial variations in crime occurrences and identify factors influencing crime patterns at the neighborhood level.
•	Clustering Analysis: Apply clustering algorithms to group similar types of crimes or neighborhoods based on specific characteristics. Gain insights into common crime profiles and underlying factors contributing to crime patterns.
Data Source The analysis is based on a comprehensive dataset of Vancouver crime incidents sourced from the Vancouver Police Open Data. The dataset contains crime records from the year 2003 to 2023, capturing two decades of data. It will be updated weekly, providing a valuable and up-to-date resource for understanding crime trends and patterns within the city.
This script performs data cleaning, and outlier detection on the raw crime dataset. It handles missing values, removes duplicates, and identifies potential outliers using appropriate techniques. Additionally, new columns or features are added to the dataset to enrich the information and aid in a more accurate analysis. The cleaned data is then saved as a pickle file for subsequent analysis and exploratory data analysis (EDA).
The steps:
1.Import Libraries
2.Read datasets
3.Quickly explore the data
There is a positive trend in Vancouver's population growth.\
Given this significant increase, I will investigate to see if there is a relationship between the population growth and\
the crime rate in EDA.")
Crime dataset includes 879861 rows and 10 columns.

There is noticeable fluctuation in 'Annual Percent Change' which represents the year-on-year change in the CPI.
The All Items Index rises over the years, showing a general rising trend. In other words, the overall price level of goods and services has been increasing over time.
It would be interesting to see if there's a correlation between economic conditions (as indicated by the CPI and its fluctuations) and crime rates. Economic downturns, for instance, might see spikes in certain types of crime. I will discover it in EDA.
4.Data cleaning
-Finding missing data
-Dealing with missing data
We have 144 missing values for NEIGHBOURHOOD which is 0.02% of the dataset.
We have 12 missing values for HUNDRED_BLOCKS which is 0.00% of the dataset.
We have 76 missing values for X which is 0.01% of the dataset.
We have 76 missing values for Y which is 0.01% of the dataset.

Let's see if we can identify the missing neighbourhoods using the corresponding values in the 'hundred_block' column. Below is the list of 'HUNDRED_BLOCKS' for which the corresponding 'NEIGHBOURHOOD' is null:
We're observing multiple different values for the neighbourhood column for a specific hundredblock. So, it seems it is not possible to identify the NEIGHBOURHOOD from the HUNDRED_BLOCKS.
Finding Inconsistant texts and typos -Fixing Inconsistant texts and typos
- Remove Block number from the Street Name
HUNDRED_BLOCK is a Generalized location of the reported crime activity.
XX NK_LOC ST is default location value used for incidents with unknown location and is geolocated to 312 Main Street.

Finding Duplicates -Removing Duplicates
here are 32046 duplicate rows in the crime dataset.

Duplicate records here might be because of different aspects of the same incident:Sometimes, a single incident might involve multiple offenses or different types of crimes. In this specific project, furthur investgation is not possible, so I assumed that the duplicates are because of data entrye error and removed them.
Finding outliers
-Dealing with outliers
I will change x,y to lat,long in the next step and again check for the outliers.
Latitude and longitude are based on the Earth's curved surface and are ideal for global measurements and navigation.In contrast, X-Y coordinates are typically based on a flat surface.

5-Create New columns
-Add a Date column to Crime Data
- Add a YearMonth column
- Add a new column to indicate holiday or not
3.42% of the crimes happend on holidays. We will discover more.
 Add two columns for day of week and weekend or weekday
- Add a column to show timeinterval
- Adding "Time Segment" column to indicate the time of day, such as morning, afternoon, evening, or night
- Add a column for crime type category
To simplify the analysis and gain a clearer perspective on crime trends, I will group the *11* distinct crime types in the dataset into broader categories based on their similarity.
- Transform UTM coordinate - Add a column for lat and lon
- Create a dataframe : Yearly Aggregation
I created a new dataframe with granularity set to 'year', then merged it with the population and CPI data. I also added the crime per capita and crime growth rate to facilitate comparison with population and CPI trends.
** Data has been cleaned. Ten columns have been added to the Crime data.
.date : date of the crime occurance
.is_holiday : showing that it was a holiday or not
.holiday : BC's holiday
.weekday : day of week
.day_type : showing that it is a weekday or weekend
.time : time the crime occured
.time_category : time segment
.crime_type_category : category of the crime type
.lon : lat long coordinate
.lat : lat long coordinate
6-Create PICKE file
Export the data to csv in order to use in PowerBI
The number of outliers based on IQR method is :
_Column lon: 61327, which is 7.23% of the dataset
_Column lat: 45134, which is 5.32% of the dataset
